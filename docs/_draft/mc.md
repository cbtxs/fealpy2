# "Monte Carlo Strategies in Scientific Computing" by Jun S. Liu

最早阐明 Monte Carlo 计算方法的实验就是 “Buffon’s needle” 问题 （Buffon 1777）在
这个著名的实验中, 给定一个长度为 $l$ 的针，以及一个带有间隔为 $D (D>l)$
的平行线的平面。在理想情况下，可以计算出针与平行线相交的概率为 

$$
\frac{2l}{\pi D} 
$$

投掷 $N$ 次, 设相交次数的比例为 $p_N$, 则可以用如下公式估计 $\pi$ 的值

$$
\hat\pi = \lim_{N \rightarrow} frac{2l}{p_N D},
$$

当 $N$ 趋向无穷时，它会收敛于 $\pi$. 历史上有多名研究者用这个方法来估计
$\pi$ 的值. 这种通过模拟随机过程估计某个量的思想, 是现代科学计算的重要组成部分.


系统应用 Monte Carlo 方法到真实的科学计算问题，出现于电子计算的早期（1945-55）,
伴随着世界上第一台超级计算机的诞生，(MANIAC，第二次世界大战，Los Alamos). 为了
更好利用这些快速计算的"超级"机器，科学家们(Stanislaw Ulam, John Von Neumann, etc)
发明了基于**统计采样**的方法用于解决原子弹设计中裂变材料随机中子扩散的数值问题
和薛定谔方程的本征值估计. 该方法的基本思想首先由乌拉姆提出, 并在他和冯·诺依曼
一起从洛斯阿拉莫斯驱车前往拉米时在车内进行了讨论完善。据称，Nick Metropolis 
创造了“Monte Carlo”这个名字，它在推广该方法方面发挥了重要作用.

在 1950 年早期, 统计物理学家们
(N. Metropolis, A. Rosenbluth, M.Rosenbluth, A. Teller, and E. Teller) 
介绍了一种基于马尔可夫链的简单流体动态蒙特卡罗模拟方法. 该方法后来扩展到越来
越复杂的物理系统, 包括自旋玻璃模型、谐波晶体、聚合物模型等. 
20世纪80年代, 统计学家和计算机科学家为更广泛的任务开发了基于蒙特卡罗的方法, 
如组合优化、非参数统计推断（如jackknife 和 bootstrap）、缺失观测值的似然计算、
统计遗传学分析、贝叶斯建模和计算等. 20世纪90年代, 该方法开始在计算生物学中发挥
重要作用, 并被用于解决序列基序识别和复杂系谱分析问题. 现在, Monte Carlo 方法的
应用领域包括生物学、化学、计算机科学、经济和金融、工程、材料科学、物理学、统计,
以及很多其它领域. 在所有的蒙特卡罗方法中，马尔可夫链蒙特卡罗（MCMC）为处理非常
复杂的问题提供了巨大的空间, 已经成为大分子和其他物理系统研究的中心支柱. 
最近, MCMC方法引起了统计学家的广泛关注，因为该方法能够帮助他们处理更复杂和实际的
统计模型。


由于被蒙特卡罗方法的极大灵活性和威力所吸引, 不同科学领域的许多研究人员为其发展
做出了贡献. 然而, 由于需要大量特定领域的知识才能理解这些领域中的问题, 因此这些
领域的研究人员之间的交流非常有限, 导致不同领域的许多努力都花费相同技术的重新发
明上. 因此, 有必要建立一个相对一般的框架, 使各个领域的科学家——例如理论化学家、
统计物理学家、结构生物学家、统计学家、计量经济学家和计算机科学家——能够比较他们
的蒙特卡罗技术并相互学习. 对于大量采用蒙特卡罗模拟和相关全局优化技术的科学家和
工程师（如模拟退火）作为他们工作中的一个重要工具，还需要跟上蒙特卡罗方法的最新
进展, 并了解各种方法的性质和联系. 这本书的目的是为蒙特卡罗方法提供一个独立、
统一且最新的处理方法。



本书旨在为三类读者服务：专门研究蒙特卡罗算法的研究人员；
对使用先进的蒙特卡罗技术感兴趣的科学家；
还有想学习蒙特卡罗计算的统计学、计算生物学和计算机科学的研究生. 理解本书中描述
的大多数方法的先决条件非常简单: 一个学期的概率论课程（Pitman 1993）和一个学期的
理论统计课程（Rice 1994）, 都是本科水平即可. 然而, 如果读者具有特定科学领域的
背景, 如人工智能、计算生物学、计算机视觉、工程或贝叶斯统计等，则更好一点，因为
这些领域涉及大量计算. 这本书最适合研究生二年级的蒙特卡罗方法课程，重点强调科学
和统计研究的相关性.

作者非常感谢他的导师和朋友王永雄的许多重要建议，他对蒙特卡罗和科学问题的热情，以及他不断的鼓励。

# 为什么需要 Monte Carlo 技术？

计算积分是很多科学计算问题的重要组成部分

$$
I = \int_D g(x)\mathrm d x,
$$

其中 $D$ 通常是高维空间中的一个区域, $g(x)$ 是待积分的目标函数. 在区域 
$D$ 中抽取独立同分布的 $m$ 个随机样本 
$\mathbf x^{(1)}, \mathbf x^{(2)}, \cdots, \mathbf x^{(m)}$

$$
\hat I_m = \frac{1}{m}\left[g(\mathbf x^{(1)}) +  \cdots 
+ g(\mathbf x^{(m)}) \right].
$$

**大数定律**(Law of Large Numbers)表明, 许多具有共同的均值和有限方差的独立随机变量
的平均值以概率 1 收敛于其共同均值, 即 

$$
\lim_{m\rightarrow \infty} \hat I_m = I, \text{with probalility} 1.
$$

它的收敛率可以由**中心极限定理**(Central Limit Theorem, CLT)估计:

$$
\sqrt{m}(\hat I_m - I) \rightarrow N(0, \sigma^2), \text{ in distribution},
$$

其中 $\sigma^2 = \text{var}\{g(\mathbf x)\}$. 因此蒙特卡罗逼近的误差项是 
$O(m^{1/2})$, 与随机变量 $\mathbf x$ 的维数无关. 这一基本背景是蒙特卡罗方法在
科学和统计学中应用潜力无限的基础。

举例说明蒙特卡罗在积分方面相对于其它确定性方法的优势.

尽管蒙特卡罗积分方法的收敛率在高维问题中保持不变，但还有两个本质的困难:
(a) 当区域 $D$ 在高维空间中较大时, 方差 $\sigma^2$ 可能会非常大, 它衡量函数
$g$ 在区域 $D$ 中的“一致性”; 
(b) 可能无法在任意区域 $D$ 中都产生均匀的随机样本. 为了克服这些困难,
研究人员通常采用**重要性采样(importance sampling)**的思想, 它从一个非均匀的分布
$\pi(\mathbf x)$ 中进行随机抽样得到 $m$ 个样本
$\mathbf x^{(1)}, \mathbf x^{(2)}, \cdots, \mathbf x^{(m)}$
这样会把更多的概率质量(probalility mass)放在**状态空间** $D$ 的重要部分上.
这样就可以估计积分 $I$ 为

$$
\hat{\hat I} = \frac{1}{m}\sum_{j=1}^m\frac{g(\mathbf x^{(j)})}{\pi(\mathbf
x^{(j)})}
$$

对应的方差为 $\sigma_\pi^2 = \text{var}_{\pi}\{g(\mathbf x)/\pi(\mathbf x)\}$. 
在理想情况下, 如果 $g$ 是非负的, $I$ 是有限的, 选择 $\pi(\mathbf x) \propto
g(\mathbf x)$ (成比例?), 会得到 $I$ 准确估计. 但是到目前为止,
没有一个蒙特卡罗的应用发生过这样幸运的事情. 更现实的情形是, 我们希望找到一个好的
候选 $\pi$, 它会在 $g$ 取值大的地方抽取更多的样本. 这种情况下, 如何从 $\pi$
中抽取随机数是一个挑战性的问题.

从一个非均匀分布 $\pi$ 中采样的需求, 也可以从生物信息学, 计算化学, 物理学, 
结构生物学, 统计学等领域中看到. 在这些问题当中, 描述复杂系统的概率分布
$\pi(\mathbf x)$ 来自物理和统计推断中的定律. 例如, 对大分子的研究中, $\mathbf x$ 
代表一个分子的结构, 形式为分子中所有原子的三维坐标. 目标概率分布由 Boltzmann 
分布定义

$$
\pi(\mathbf x) = Z(T)e^{-h(\mathbf x)/kT},
$$

其中 $k$ 是 Boltzmann 常数, $T$ 是系统温度, $h(\mathbf x)$ 是系统能量函数,
$Z(T)$ 是配分函数(partition function), 非常难以计算. 科学家通常对系统的平均特征
感兴趣, 其中很多可以在数学上表达为 $E_\pi[g(\mathbf x)]$ 的形式, 其中 $g$
是一个适当定义的函数. 在贝叶斯统计推断中, $\mathbf x$
通常表示缺失数据和参数值之间的**联合配置(joint configuration)**, $\pi(\mathbf
x)$ 通常是这些变量的后验分布. 人们必须综合掉干扰参数和缺失的数据, 
以便对感兴趣的参数作出适当的推断, 并对未来的观测作出有效的预测. 
这些任务可以再次表示为计算配置空间函数的期望值.

有时, 一个最优化问题也可以表达为一个 Monte Carlo 采样问题.
假设我们想找到一个目标函数 $g(\mathbf x)$ 的最小值, 它定义在一个很可能非常复杂的
配置空间中. 这个问题等价于找到另一个函数的最大值, 

$$
q_T(\mathbf x) = e^{-h(\mathbf x)/T}
$$

其中 $T>0$. 当 $q_T(\mathbf x)$ 关于所有的 $T>0$
都是可积的(这是实际应用中常见的情况), 我们可以构造一族概率分布

$$
\pi_T(\mathbf x) = \propto e^{-h(\mathbf x)/T}, T> 0.
$$

当 $T$ 足够小的的时候, 如果我们从 $\pi_T(\mathbf x)$ 中采样,
得到的随机值很有可能落在 $h(\mathbf x)$ 的附近.
这种思想是著名的模拟退火算法(Kirkpatrick et al. 1983)的基础, 也是设计更有效的
蒙特卡罗算法的回火技术的关键.

## 1.2 本书的范围和大纲

了解这些方法的性质和特点, 揭示它们之间的联系和差异，比较它们的性能并进行推广和一
般化，并展示它们在科学和统计问题中的应用。

本章的剩余部分介绍了统计物理、分子模拟、生物信息学、动力系统分析、统计假设检验、
分层模型的贝叶斯推理以及其他统计缺失数据问题中的启发性的例子(motivating
examples)

## 1.3 统计物理中的计算

科学家通常对来自 Boltzmann 分布(Gibbs 分布)的模拟感兴趣, 它通常有如下形式

$$
\pi(\mathbf x) = \frac{1}{Z}e^{-U(\mathbf x)/kT},
$$

其中 $\mathbf x$ 是物理系统的一个特定配置, $U(\mathbf x)$ 是它的势能, $T$
是温度, $k$ 是 Boltzmann 常数. 函数 $Z = Z(T)$ 称为**配分函数(partition
function)**(在非物理领域又叫规范化常量).

易辛模型(Ising model) 是一个以物理学家恩斯特.伊辛命名的数学模型, 它描述了磁铁的
行为, 是统计物理中最著名, 研究最彻底的模型. 该模型背后的直觉是, 一块材料的磁性
是该材料中许多原子自旋的偶极矩的集体贡献.

自由能, 是指一个热力学系统中可以用来对外做功的部分, 是热力学状态函数.

**比热(specific heat)** 是内能关于温度的导数

一个系统的熵(entropy) 

$$
S = \frac{<U> - F}{T}
$$

内能减去自由能除以温度

## 1.4 分子结构模拟

扭转角, 也称为二面角, 由一个分子中的三个连续键形成,
并由两个外部键之间的角度定义.

Hydrogen bond: 氢键 0.18 nm
Covalent Bond: 共阶键 0.10 nm 

基因调控: gene regulation

估计比热和自由能

在蛋白质折叠问题中, 有趣的问题是找到系统最小能量配置

## 1.5 Bioinformatics: Finding Weak Repetitive Patterns

生物信息学: 寻找弱重复模式

线性生物聚合物(linear biopolymers): 
* DNA : 信息存储分子
* RNA
* 蛋白质
是构成生命的三个核心分子模块.

个体有机体的所有遗传信息都包含在其基因组中，基因组由四个DNA碱基
（核苷酸）、A、T、C和G的序列组成。

RNA有着广泛的作用, 包括一系列小而重要的功能.

蛋白质是由20个不同氨基酸残基(residues) 组成的链, 是生命的
作用分子(功能分子, action molecules), 负责几乎所有生物的所有功能, 
并形成多样的生命结构。

遗传信息如何从DNA到RNA再到蛋白质被认为是分子生物学的中心范式.

分析生物序列数据的一个重要问题是找到多个蛋白质或DNA序列共享的模式,
它与**局部序列比对任务**密切相关.

## 1.6 非线性动态系统:目标跟踪

动态建模广泛应用于计算机视觉、经济数据分析、反馈控制系统、移动通信、
雷达或声纳监视系统等领域.

在这样一个动态系统中, 一个重要的问题是关于系统特性信息（如估计和预测）的在线
（实时）处理. 在工程和统计文献中, 这些任务通常被称为“过滤”. 这些领域的研究人
员面临的一个主要挑战是找到有效的滤波算法.

杂波环境中的目标跟踪, 如图1.7所示是动态建模的典型示例.

## 1.7 天文观测的假设检验

## 1.8 多级模型的贝叶斯推理

## 1.9 蒙特卡罗与缺失数据问题
